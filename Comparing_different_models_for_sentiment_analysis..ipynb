{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_git.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_c3AEvyJ-wx",
        "outputId": "ea5351bc-d998-4133-d07a-0e5a4f3f08d1"
      },
      "source": [
        "#GPU information\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 31 12:17:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRl9owdGKG8W",
        "outputId": "bee69f79-9623-4641-d4db-689c37efc432"
      },
      "source": [
        "#Mounting the Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONQrAMBWKL8e",
        "outputId": "dfa4b3f4-4dab-4f0e-9cb6-990f600b3fcc"
      },
      "source": [
        "#Changing working directory\n",
        "%cd /content/gdrive/My Drive/ML-in-colab/Sentiment_analysis_amazon_fine_food_review"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/ML-in-colab/Sentiment_analysis_amazon_fine_food_review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfQiiT_wKR_J",
        "outputId": "1ea1da4f-347e-4d2c-c998-a376618fb584"
      },
      "source": [
        "#Installing Dependencies\n",
        "!pip install tensorflow_text"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/ed/bbb51e9eccca0c2bfdf9df66e54cdff563b6f32daed9255da9b9a541368f/tensorflow_text-2.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.34.1)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.8.0->tensorflow_text) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.30.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.4.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.1.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1USPSVeGKYpZ"
      },
      "source": [
        "#Importing Liabries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "izWqszsCKYr3",
        "outputId": "e631f607-31d5-48df-d49e-882659742372"
      },
      "source": [
        "#Loading Data into DataFrame\n",
        "data = pd.read_csv('data/preprocessed_reviews.csv')\n",
        "data = data[:15000] # we are limiting ourself to 15k Reviews because of Computational Constraint\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i recently purchased a bottle each of the suga...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is an excellent gluten free alternative t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my dog and i both love this product my vet eve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your friends and family may envy you when you ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>these should have an age limit i do not think ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Score\n",
              "0  i recently purchased a bottle each of the suga...      0\n",
              "1  this is an excellent gluten free alternative t...      1\n",
              "2  my dog and i both love this product my vet eve...      1\n",
              "3  your friends and family may envy you when you ...      1\n",
              "4  these should have an age limit i do not think ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWSaR64bKYuP",
        "outputId": "c90b12ec-dcd1-45f9-9b05-2cdf8cf9a8a0"
      },
      "source": [
        "def removeDup(df):\n",
        "  if df.duplicated().any() == True:\n",
        "    print(\"Found {} duplicated\".format(df.duplicated().sum()))\n",
        "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
        "    print(\"Duplicated removed\")\n",
        "    return df\n",
        "  else:\n",
        "    print(\"Duplicates not found\")\n",
        "    return df\n",
        "\n",
        "data = removeDup(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 34 duplicated\n",
            "Duplicated removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Do4HbQKYwS",
        "outputId": "de87c5d8-ec51-47f7-a250-d3d82b7812d9"
      },
      "source": [
        "#Checking and removing Null values if any\n",
        "\n",
        "def removeNull(df):\n",
        "  \"This function will check Duplicated and remove if any \"\n",
        "  if df.isnull().any().any() == True:\n",
        "    print(\"Found {} Null values\".format(df.isnull().values.sum()))\n",
        "    df.dropna(inplace=True)\n",
        "    print(\"Null Values Dropped\")\n",
        "    return df\n",
        "  else:\n",
        "    print(\"No Null value found\")\n",
        "    return df\n",
        "\n",
        "data = removeNull(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2 Null values\n",
            "Null Values Dropped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJD6dm-wKlAV",
        "outputId": "c3f4ac26-aa27-45cb-c60f-902a9d23b6bb"
      },
      "source": [
        "#Spliting tha data into train test\n",
        "\n",
        "train_size = 0.668  #Spliting to get nearly 10k in training and 5k in testing\n",
        "train_data, test_data = train_test_split(data, train_size= train_size, shuffle=True)\n",
        "print(\"Length of Train Data:\",len(train_data))\n",
        "print(\"Length of Test Data:\",len(test_data))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train Data: 9995\n",
            "Length of Test Data: 4969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-MFXKTQQ0S"
      },
      "source": [
        "**MLP Model - bert Large as embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at22ZMPQLPX9"
      },
      "source": [
        "#Importing Bert pretrained model from Tensorflow Hub\n",
        "preprocess_model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "bert_encoder_model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
        "\n",
        "precessing_layer = hub.KerasLayer( preprocess_model_url)\n",
        "bert_layer = hub.KerasLayer( bert_encoder_model_url, trainable = False )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTfeZIG5QXqo"
      },
      "source": [
        "#Creating MLP Model\n",
        "\n",
        "def normalModel(precessing_layer, bert_layer):\n",
        "  input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "  encorder_input = precessing_layer(input)\n",
        "  encorder_output = bert_layer(encorder_input)\n",
        "  final_output = encorder_output['pooled_output']\n",
        "  x = tf.keras.layers.Dense(1024, activation='relu')(final_output)\n",
        "  x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "  model = tf.keras.Model(input, x)\n",
        "\n",
        "  model.compile(loss='BinaryCrossentropy' , optimizer = Adam(learning_rate=1e-5), metrics= 'BinaryAccuracy' )\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK9jCUKiQdNN"
      },
      "source": [
        "**N.P - Bert large model is only used for converting our text to numerical form so that we can apply MLP here Which makes it a MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZifHjkAQZcZ",
        "outputId": "762cd674-9712-40d1-dfa7-5b8cdb7ba4d7"
      },
      "source": [
        "mlp_model = normalModel(precessing_layer, bert_layer)\n",
        "mlp_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        {'input_word_ids': ( 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)      {'encoder_outputs':  335141889   keras_layer[0][0]                \n",
            "                                                                 keras_layer[0][1]                \n",
            "                                                                 keras_layer[0][2]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         1049600     keras_layer_1[0][25]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2048)         2099200     dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2048)         4196352     dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1024)         2098176     dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            1025        dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 344,586,242\n",
            "Trainable params: 9,444,353\n",
            "Non-trainable params: 335,141,889\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a_1lKsSQhIh",
        "outputId": "31a8b0af-a9ad-4265-8a40-3f7a37e6a03e"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Training our MLP Model\n",
        "mlp_model_history = mlp_model.fit(x = train_data['Text'].to_numpy(), y = train_data['Score'].to_numpy(),batch_size = 32,\n",
        "                    validation_data = (test_data['Text'].to_numpy(), test_data['Score'].to_numpy() ),\n",
        "                               epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 267s 805ms/step - loss: 0.6787 - binary_accuracy: 0.5681 - val_loss: 0.6807 - val_binary_accuracy: 0.5506\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 251s 803ms/step - loss: 0.6375 - binary_accuracy: 0.6498 - val_loss: 0.6071 - val_binary_accuracy: 0.6981\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 251s 803ms/step - loss: 0.5897 - binary_accuracy: 0.6988 - val_loss: 0.5485 - val_binary_accuracy: 0.7519\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 251s 803ms/step - loss: 0.5392 - binary_accuracy: 0.7381 - val_loss: 0.5015 - val_binary_accuracy: 0.7744\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 251s 803ms/step - loss: 0.4962 - binary_accuracy: 0.7677 - val_loss: 0.4742 - val_binary_accuracy: 0.7802\n",
            "CPU times: user 6min 22s, sys: 3min 3s, total: 9min 25s\n",
            "Wall time: 21min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__OpPWuYihaQ"
      },
      "source": [
        "**MLP model - Bert Small as Embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLMcjHaNihmR"
      },
      "source": [
        "preprocess_model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "bert_small_model_url = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "\n",
        "precessing_layer = hub.KerasLayer( preprocess_model_url)\n",
        "bert_small_layer = hub.KerasLayer( bert_small_model_url, trainable = False )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ0J3tYFihw1"
      },
      "source": [
        "#Creating MLP model \n",
        "\n",
        "def small_model(precessing_layer, bert_layer):\n",
        "  input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "  encorder_input = precessing_layer(input)\n",
        "  encorder_output = bert_layer(encorder_input)\n",
        "  final_output = encorder_output['pooled_output']\n",
        "  x = tf.keras.layers.Dense(512, activation='relu')(final_output)\n",
        "  x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "  model = tf.keras.Model(input, x)\n",
        "  \n",
        "  model.compile(loss='BinaryCrossentropy' , optimizer = Adam(learning_rate=1e-5), metrics= 'BinaryAccuracy' )\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paw-vyTnUHqU"
      },
      "source": [
        "**N.P - Bert small model is only used for converting our text to numerical form so that we can apply MLP here Which makes it a MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaeZWJ0Ti6gg",
        "outputId": "69e4d8d2-47dc-4204-80d1-0eb713a15ca4"
      },
      "source": [
        "bert_small_model = small_model(precessing_layer, bert_small_layer)\n",
        "bert_small_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_2 (KerasLayer)      {'input_word_ids': ( 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_3 (KerasLayer)      {'sequence_output':  28763649    keras_layer_2[0][0]              \n",
            "                                                                 keras_layer_2[0][1]              \n",
            "                                                                 keras_layer_2[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          262656      keras_layer_3[0][5]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1024)         525312      dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1024)         1049600     dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 512)          524800      dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            513         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 31,126,530\n",
            "Trainable params: 2,362,881\n",
            "Non-trainable params: 28,763,649\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1u6E8Khih2y",
        "outputId": "ded6c3ef-7b17-4f5f-a6e7-cdb5a9b3380a"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Training our MLP model\n",
        "bert_small_history = bert_small_model.fit(x = train_data['Text'].to_numpy(), y = train_data['Score'].to_numpy(),batch_size = 32,\n",
        "                    validation_data = (test_data['Text'].to_numpy(), test_data['Score'].to_numpy() ),\n",
        "                               epochs=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 40s 120ms/step - loss: 0.5747 - binary_accuracy: 0.7235 - val_loss: 0.4948 - val_binary_accuracy: 0.7627\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 37s 119ms/step - loss: 0.4678 - binary_accuracy: 0.7774 - val_loss: 0.4548 - val_binary_accuracy: 0.7909\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 37s 119ms/step - loss: 0.4449 - binary_accuracy: 0.7919 - val_loss: 0.4477 - val_binary_accuracy: 0.7977\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 37s 119ms/step - loss: 0.4335 - binary_accuracy: 0.7946 - val_loss: 0.4470 - val_binary_accuracy: 0.7961\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 37s 118ms/step - loss: 0.4254 - binary_accuracy: 0.7983 - val_loss: 0.4346 - val_binary_accuracy: 0.8014\n",
            "CPU times: user 2min 57s, sys: 36.4 s, total: 3min 33s\n",
            "Wall time: 3min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc1tJ8pzdr8g"
      },
      "source": [
        "**Bert Large Trainable model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a19UZEN7dw7T"
      },
      "source": [
        "#Importing Bert pretrained model from Tensorflow Hub\n",
        "preprocess_model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "bert_encoder_model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
        "\n",
        "precessing_layer = hub.KerasLayer( preprocess_model_url)\n",
        "bert_layer = hub.KerasLayer( bert_encoder_model_url, trainable = True )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn-TMzgRdyHE"
      },
      "source": [
        "#Creating Bert model\n",
        "\n",
        "def bert_Model(precessing_layer, bert_layer):\n",
        "  input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "  encorder_input = precessing_layer(input)\n",
        "  encorder_output = bert_layer(encorder_input)\n",
        "  final_output = encorder_output['pooled_output']\n",
        "  x = tf.keras.layers.Dense(1, activation='sigmoid')(final_output)\n",
        "  model = tf.keras.Model(input, x)\n",
        "\n",
        "  model.compile(loss='BinaryCrossentropy' , optimizer = Adam(learning_rate=1e-5), metrics= 'BinaryAccuracy' )\n",
        "  return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EuC1XFQdyJZ",
        "outputId": "196d0835-dbde-418a-e65f-e1e23370528b"
      },
      "source": [
        "bert_model = bert_Model(precessing_layer, bert_layer)\n",
        "bert_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_4 (KerasLayer)      {'input_word_ids': ( 0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_5 (KerasLayer)      {'encoder_outputs':  335141889   keras_layer_4[0][0]              \n",
            "                                                                 keras_layer_4[0][1]              \n",
            "                                                                 keras_layer_4[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            1025        keras_layer_5[0][25]             \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdOadgp_dyMC",
        "outputId": "f126bde4-8f1a-4ab7-a6c2-bac086c7b28b"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Training our Bert Large Model\n",
        "bert_model_history = bert_model.fit(x = train_data['Text'].to_numpy(), y = train_data['Score'].to_numpy(),batch_size = 16,\n",
        "                    validation_data = (test_data['Text'].to_numpy(), test_data['Score'].to_numpy() ),\n",
        "                               epochs=3)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 632s 977ms/step - loss: 0.2468 - binary_accuracy: 0.8961 - val_loss: 0.1819 - val_binary_accuracy: 0.9288\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 609s 975ms/step - loss: 0.1164 - binary_accuracy: 0.9587 - val_loss: 0.1819 - val_binary_accuracy: 0.9278\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 609s 975ms/step - loss: 0.0639 - binary_accuracy: 0.9784 - val_loss: 0.2033 - val_binary_accuracy: 0.9362\n",
            "CPU times: user 18min 14s, sys: 8min 1s, total: 26min 15s\n",
            "Wall time: 30min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}